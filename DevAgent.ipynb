{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ab701fc-af07-4398-a041-b79ee607c484",
   "metadata": {},
   "source": [
    "SÃ©lectionner un dÃ©pÃ´t GitHub test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e8009b5-78fa-4b4e-9f79-c3bd120daf76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš¡ Repo dÃ©jÃ  clonÃ©\n"
     ]
    }
   ],
   "source": [
    "from git import Repo\n",
    "import os\n",
    "\n",
    "# Dossier oÃ¹ on stocke les dÃ©pÃ´ts clonÃ©s\n",
    "os.makedirs(\"repos\", exist_ok=True)\n",
    "\n",
    "# Exemple : cloner un repo public\n",
    "repo_url = \"https://github.com/psf/requests.git\"  # tu peux changer lâ€™URL\n",
    "local_path = \"repos/requests\"\n",
    "\n",
    "if not os.path.exists(local_path):\n",
    "    Repo.clone_from(repo_url, local_path)\n",
    "    print(f\"âœ… Repo clonÃ© : {repo_url}\")\n",
    "else:\n",
    "    print(\"âš¡ Repo dÃ©jÃ  clonÃ©\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b314f5-eb72-47b2-a5b2-9587eefa685f",
   "metadata": {},
   "source": [
    "TÃ©lÃ©charger CodeSearchNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72aa53ee-4e68-4f2f-a2b3-73ac6e2ff680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['repo', 'path', 'func_name', 'original_string', 'language', 'code', 'code_tokens', 'docstring', 'docstring_tokens', 'sha', 'url', 'partition', 'summary'],\n",
      "        num_rows: 455243\n",
      "    })\n",
      "})\n",
      "{'repo': 'ageitgey/face_recognition', 'path': 'examples/face_recognition_knn.py', 'func_name': 'train', 'original_string': 'def train(train_dir, model_save_path=None, n_neighbors=None, knn_algo=\\'ball_tree\\', verbose=False):\\n    \"\"\"\\n    Trains a k-nearest neighbors classifier for face recognition.\\n\\n    :param train_dir: directory that contains a sub-directory for each known person, with its name.\\n\\n     (View in source code to see train_dir example tree structure)\\n\\n     Structure:\\n        <train_dir>/\\n        â”œâ”€â”€ <person1>/\\n        â”‚   â”œâ”€â”€ <somename1>.jpeg\\n        â”‚   â”œâ”€â”€ <somename2>.jpeg\\n        â”‚   â”œâ”€â”€ ...\\n        â”œâ”€â”€ <person2>/\\n        â”‚   â”œâ”€â”€ <somename1>.jpeg\\n        â”‚   â””â”€â”€ <somename2>.jpeg\\n        â””â”€â”€ ...\\n\\n    :param model_save_path: (optional) path to save model on disk\\n    :param n_neighbors: (optional) number of neighbors to weigh in classification. Chosen automatically if not specified\\n    :param knn_algo: (optional) underlying data structure to support knn.default is ball_tree\\n    :param verbose: verbosity of training\\n    :return: returns knn classifier that was trained on the given data.\\n    \"\"\"\\n    X = []\\n    y = []\\n\\n    # Loop through each person in the training set\\n    for class_dir in os.listdir(train_dir):\\n        if not os.path.isdir(os.path.join(train_dir, class_dir)):\\n            continue\\n\\n        # Loop through each training image for the current person\\n        for img_path in image_files_in_folder(os.path.join(train_dir, class_dir)):\\n            image = face_recognition.load_image_file(img_path)\\n            face_bounding_boxes = face_recognition.face_locations(image)\\n\\n            if len(face_bounding_boxes) != 1:\\n                # If there are no people (or too many people) in a training image, skip the image.\\n                if verbose:\\n                    print(\"Image {} not suitable for training: {}\".format(img_path, \"Didn\\'t find a face\" if len(face_bounding_boxes) < 1 else \"Found more than one face\"))\\n            else:\\n                # Add face encoding for current image to the training set\\n                X.append(face_recognition.face_encodings(image, known_face_locations=face_bounding_boxes)[0])\\n                y.append(class_dir)\\n\\n    # Determine how many neighbors to use for weighting in the KNN classifier\\n    if n_neighbors is None:\\n        n_neighbors = int(round(math.sqrt(len(X))))\\n        if verbose:\\n            print(\"Chose n_neighbors automatically:\", n_neighbors)\\n\\n    # Create and train the KNN classifier\\n    knn_clf = neighbors.KNeighborsClassifier(n_neighbors=n_neighbors, algorithm=knn_algo, weights=\\'distance\\')\\n    knn_clf.fit(X, y)\\n\\n    # Save the trained KNN classifier\\n    if model_save_path is not None:\\n        with open(model_save_path, \\'wb\\') as f:\\n            pickle.dump(knn_clf, f)\\n\\n    return knn_clf', 'language': 'python', 'code': 'def train(train_dir, model_save_path=None, n_neighbors=None, knn_algo=\\'ball_tree\\', verbose=False):\\n    \"\"\"\\n    Trains a k-nearest neighbors classifier for face recognition.\\n\\n    :param train_dir: directory that contains a sub-directory for each known person, with its name.\\n\\n     (View in source code to see train_dir example tree structure)\\n\\n     Structure:\\n        <train_dir>/\\n        â”œâ”€â”€ <person1>/\\n        â”‚   â”œâ”€â”€ <somename1>.jpeg\\n        â”‚   â”œâ”€â”€ <somename2>.jpeg\\n        â”‚   â”œâ”€â”€ ...\\n        â”œâ”€â”€ <person2>/\\n        â”‚   â”œâ”€â”€ <somename1>.jpeg\\n        â”‚   â””â”€â”€ <somename2>.jpeg\\n        â””â”€â”€ ...\\n\\n    :param model_save_path: (optional) path to save model on disk\\n    :param n_neighbors: (optional) number of neighbors to weigh in classification. Chosen automatically if not specified\\n    :param knn_algo: (optional) underlying data structure to support knn.default is ball_tree\\n    :param verbose: verbosity of training\\n    :return: returns knn classifier that was trained on the given data.\\n    \"\"\"\\n    X = []\\n    y = []\\n\\n    # Loop through each person in the training set\\n    for class_dir in os.listdir(train_dir):\\n        if not os.path.isdir(os.path.join(train_dir, class_dir)):\\n            continue\\n\\n        # Loop through each training image for the current person\\n        for img_path in image_files_in_folder(os.path.join(train_dir, class_dir)):\\n            image = face_recognition.load_image_file(img_path)\\n            face_bounding_boxes = face_recognition.face_locations(image)\\n\\n            if len(face_bounding_boxes) != 1:\\n                # If there are no people (or too many people) in a training image, skip the image.\\n                if verbose:\\n                    print(\"Image {} not suitable for training: {}\".format(img_path, \"Didn\\'t find a face\" if len(face_bounding_boxes) < 1 else \"Found more than one face\"))\\n            else:\\n                # Add face encoding for current image to the training set\\n                X.append(face_recognition.face_encodings(image, known_face_locations=face_bounding_boxes)[0])\\n                y.append(class_dir)\\n\\n    # Determine how many neighbors to use for weighting in the KNN classifier\\n    if n_neighbors is None:\\n        n_neighbors = int(round(math.sqrt(len(X))))\\n        if verbose:\\n            print(\"Chose n_neighbors automatically:\", n_neighbors)\\n\\n    # Create and train the KNN classifier\\n    knn_clf = neighbors.KNeighborsClassifier(n_neighbors=n_neighbors, algorithm=knn_algo, weights=\\'distance\\')\\n    knn_clf.fit(X, y)\\n\\n    # Save the trained KNN classifier\\n    if model_save_path is not None:\\n        with open(model_save_path, \\'wb\\') as f:\\n            pickle.dump(knn_clf, f)\\n\\n    return knn_clf', 'code_tokens': ['def', 'train', '(', 'train_dir', ',', 'model_save_path', '=', 'None', ',', 'n_neighbors', '=', 'None', ',', 'knn_algo', '=', \"'ball_tree'\", ',', 'verbose', '=', 'False', ')', ':', 'X', '=', '[', ']', 'y', '=', '[', ']', '# Loop through each person in the training set', 'for', 'class_dir', 'in', 'os', '.', 'listdir', '(', 'train_dir', ')', ':', 'if', 'not', 'os', '.', 'path', '.', 'isdir', '(', 'os', '.', 'path', '.', 'join', '(', 'train_dir', ',', 'class_dir', ')', ')', ':', 'continue', '# Loop through each training image for the current person', 'for', 'img_path', 'in', 'image_files_in_folder', '(', 'os', '.', 'path', '.', 'join', '(', 'train_dir', ',', 'class_dir', ')', ')', ':', 'image', '=', 'face_recognition', '.', 'load_image_file', '(', 'img_path', ')', 'face_bounding_boxes', '=', 'face_recognition', '.', 'face_locations', '(', 'image', ')', 'if', 'len', '(', 'face_bounding_boxes', ')', '!=', '1', ':', '# If there are no people (or too many people) in a training image, skip the image.', 'if', 'verbose', ':', 'print', '(', '\"Image {} not suitable for training: {}\"', '.', 'format', '(', 'img_path', ',', '\"Didn\\'t find a face\"', 'if', 'len', '(', 'face_bounding_boxes', ')', '<', '1', 'else', '\"Found more than one face\"', ')', ')', 'else', ':', '# Add face encoding for current image to the training set', 'X', '.', 'append', '(', 'face_recognition', '.', 'face_encodings', '(', 'image', ',', 'known_face_locations', '=', 'face_bounding_boxes', ')', '[', '0', ']', ')', 'y', '.', 'append', '(', 'class_dir', ')', '# Determine how many neighbors to use for weighting in the KNN classifier', 'if', 'n_neighbors', 'is', 'None', ':', 'n_neighbors', '=', 'int', '(', 'round', '(', 'math', '.', 'sqrt', '(', 'len', '(', 'X', ')', ')', ')', ')', 'if', 'verbose', ':', 'print', '(', '\"Chose n_neighbors automatically:\"', ',', 'n_neighbors', ')', '# Create and train the KNN classifier', 'knn_clf', '=', 'neighbors', '.', 'KNeighborsClassifier', '(', 'n_neighbors', '=', 'n_neighbors', ',', 'algorithm', '=', 'knn_algo', ',', 'weights', '=', \"'distance'\", ')', 'knn_clf', '.', 'fit', '(', 'X', ',', 'y', ')', '# Save the trained KNN classifier', 'if', 'model_save_path', 'is', 'not', 'None', ':', 'with', 'open', '(', 'model_save_path', ',', \"'wb'\", ')', 'as', 'f', ':', 'pickle', '.', 'dump', '(', 'knn_clf', ',', 'f', ')', 'return', 'knn_clf'], 'docstring': 'Trains a k-nearest neighbors classifier for face recognition.\\n\\n    :param train_dir: directory that contains a sub-directory for each known person, with its name.\\n\\n     (View in source code to see train_dir example tree structure)\\n\\n     Structure:\\n        <train_dir>/\\n        â”œâ”€â”€ <person1>/\\n        â”‚   â”œâ”€â”€ <somename1>.jpeg\\n        â”‚   â”œâ”€â”€ <somename2>.jpeg\\n        â”‚   â”œâ”€â”€ ...\\n        â”œâ”€â”€ <person2>/\\n        â”‚   â”œâ”€â”€ <somename1>.jpeg\\n        â”‚   â””â”€â”€ <somename2>.jpeg\\n        â””â”€â”€ ...\\n\\n    :param model_save_path: (optional) path to save model on disk\\n    :param n_neighbors: (optional) number of neighbors to weigh in classification. Chosen automatically if not specified\\n    :param knn_algo: (optional) underlying data structure to support knn.default is ball_tree\\n    :param verbose: verbosity of training\\n    :return: returns knn classifier that was trained on the given data.', 'docstring_tokens': ['Trains', 'a', 'k', '-', 'nearest', 'neighbors', 'classifier', 'for', 'face', 'recognition', '.'], 'sha': 'c96b010c02f15e8eeb0f71308c641179ac1f19bb', 'url': 'https://github.com/ageitgey/face_recognition/blob/c96b010c02f15e8eeb0f71308c641179ac1f19bb/examples/face_recognition_knn.py#L46-L108', 'partition': 'train', 'summary': 'Train a k - nearest neighbors classifier for face recognition.'}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Charger une partie de CodeSearchNet (ex: Python)\n",
    "dataset = load_dataset(\"Nan-Do/code-search-net-python\")\n",
    "\n",
    "print(dataset)\n",
    "print(dataset[\"train\"][0])  # exemple dâ€™un Ã©chantillon\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af975b7-1430-47cf-8f12-1b4d71d6f4d4",
   "metadata": {},
   "source": [
    "DÃ©but de lâ€™ingestion (lecture de fichiers du repo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c7e6bb1-14fd-4165-9ef6-c629aa765410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‚ 36 fichiers trouvÃ©s\n",
      "['repos/requests\\\\setup.py', 'repos/requests\\\\docs\\\\conf.py', 'repos/requests\\\\docs\\\\_themes\\\\flask_theme_support.py', 'repos/requests\\\\src\\\\requests\\\\adapters.py', 'repos/requests\\\\src\\\\requests\\\\api.py']\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "files = glob.glob(local_path + \"/**/*.py\", recursive=True)\n",
    "\n",
    "print(f\"ðŸ“‚ {len(files)} fichiers trouvÃ©s\")\n",
    "print(files[:5])  # afficher les 5 premiers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0753d0-951f-4970-9ba4-2e6dd7150659",
   "metadata": {},
   "source": [
    "Extraire du code dâ€™un dÃ©pÃ´t GitHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "857ce60b-c4ea-43c2-8793-cf1db509d326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‚ 36 fichiers chargÃ©s depuis le repo\n",
      "setup.py\n",
      "#!/usr/bin/env python\n",
      "import os\n",
      "import sys\n",
      "from codecs import open\n",
      "\n",
      "from setuptools import setup\n",
      "\n",
      "CURRENT_PYTHON = sys.version_info[:2]\n",
      "REQUIRED_PYTHON = (3, 9)\n",
      "\n",
      "if CURRENT_PYTHON < REQUIRED_PYTHON:\n",
      "    sys.stderr.write(\n",
      "        \"\"\"\n",
      "==========================\n",
      "Unsupported Python version\n",
      "=============\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def load_repo_files(path, extensions=[\".py\"]):\n",
    "    code_files = []\n",
    "    for root, _, files in os.walk(path):\n",
    "        for f in files:\n",
    "            if any(f.endswith(ext) for ext in extensions):\n",
    "                try:\n",
    "                    with open(os.path.join(root, f), \"r\", encoding=\"utf-8\") as fp:\n",
    "                        code_files.append({\n",
    "                            \"file\": os.path.relpath(os.path.join(root, f), path),\n",
    "                            \"content\": fp.read()\n",
    "                        })\n",
    "                except Exception as e:\n",
    "                    print(f\"âš ï¸ Erreur lecture {f}: {e}\")\n",
    "    return code_files\n",
    "\n",
    "repo_code = load_repo_files(\"repos/requests\")\n",
    "print(f\"ðŸ“‚ {len(repo_code)} fichiers chargÃ©s depuis le repo\")\n",
    "print(repo_code[0][\"file\"])\n",
    "print(repo_code[0][\"content\"][:300])  # aperÃ§u\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbb3689-00ef-49bc-9b85-86e92e038a5c",
   "metadata": {},
   "source": [
    "Extraire quelques exemples de CodeSearchNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9e3bac7-38eb-45f0-85d2-58cdf03ed8f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“š 100 extraits de CodeSearchNet chargÃ©s\n",
      "Exemple fichier: codesearchnet_0.py\n",
      "Code: def train(train_dir, model_save_path=None, n_neighbors=None, knn_algo='ball_tree', verbose=False):\n",
      "    \"\"\"\n",
      "    Trains a k-nearest neighbors classifier for face recognition.\n",
      "\n",
      "    :param train_dir: dire\n",
      "Docstring: Trains a k-nearest neighbors classifier for face recognition.\n",
      "\n",
      "    :param train_dir: directory that contains a sub-directory for each known person, with its name.\n",
      "\n",
      "     (View in source code to see train_dir example tree structure)\n",
      "\n",
      "     Structure:\n",
      "        <train_dir>/\n",
      "        â”œâ”€â”€ <person1>/\n",
      "        â”‚   â”œâ”€â”€ <somename1>.jpeg\n",
      "        â”‚   â”œâ”€â”€ <somename2>.jpeg\n",
      "        â”‚   â”œâ”€â”€ ...\n",
      "        â”œâ”€â”€ <person2>/\n",
      "        â”‚   â”œâ”€â”€ <somename1>.jpeg\n",
      "        â”‚   â””â”€â”€ <somename2>.jpeg\n",
      "        â””â”€â”€ ...\n",
      "\n",
      "    :param model_save_path: (optional) path to save model on disk\n",
      "    :param n_neighbors: (optional) number of neighbors to weigh in classification. Chosen automatically if not specified\n",
      "    :param knn_algo: (optional) underlying data structure to support knn.default is ball_tree\n",
      "    :param verbose: verbosity of training\n",
      "    :return: returns knn classifier that was trained on the given data.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Charger uniquement une petite portion pour tester (100 exemples)\n",
    "dataset = load_dataset(\"Nan-Do/code-search-net-python\", split=\"train[:100]\")\n",
    "\n",
    "codesearch_samples = []\n",
    "for i, ex in enumerate(dataset):\n",
    "    code = ex[\"code\"]\n",
    "    docstring = ex.get(\"docstring\", \"\")\n",
    "    codesearch_samples.append({\n",
    "        \"file\": f\"codesearchnet_{i}.py\",\n",
    "        \"content\": code,\n",
    "        \"doc\": docstring\n",
    "    })\n",
    "\n",
    "print(f\"ðŸ“š {len(codesearch_samples)} extraits de CodeSearchNet chargÃ©s\")\n",
    "print(\"Exemple fichier:\", codesearch_samples[0][\"file\"])\n",
    "print(\"Code:\", codesearch_samples[0][\"content\"][:200])\n",
    "print(\"Docstring:\", codesearch_samples[0][\"doc\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd66977f-4b06-4a3d-8c0a-5ac6b6bfc739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error reading file repos/requests\\tests/certs/valid/ca: [Errno 13] Permission denied: 'repos/requests\\\\tests/certs/valid/ca'\n",
      "Error reading file repos/requests\\tests/certs/mtls/client/ca: [Errno 13] Permission denied: 'repos/requests\\\\tests/certs/mtls/client/ca'\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import GitLoader\n",
    "\n",
    "# Charger les fichiers du dÃ©pÃ´t clonÃ©\n",
    "loader = GitLoader(repo_path=\"repos/requests\")\n",
    "repos = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8fe621-6857-482d-853f-601808ee6117",
   "metadata": {},
   "source": [
    "Indexer dans Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e5d0c41e-dfce-49d7-8997-6f5b429ca423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Index crÃ©Ã© avec 219 documents\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# Embeddings locaux (lÃ©ger et rapide)\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# PrÃ©parer tous les documents (repo + CodeSearchNet)\n",
    "documents = repos + codesearch_samples\n",
    "\n",
    "texts = []\n",
    "metadatas = []\n",
    "\n",
    "for doc in documents:\n",
    "    # Si câ€™est un Document LangChain\n",
    "    if hasattr(doc, \"page_content\"):\n",
    "        content = doc.page_content\n",
    "        metadata = doc.metadata\n",
    "    else:\n",
    "        # Si câ€™est un dict (CodeSearchNet)\n",
    "        content = doc[\"content\"]\n",
    "        metadata = {\"doc\": doc.get(\"doc\", \"\"), \"file\": doc.get(\"file\", \"inconnu\")}\n",
    "\n",
    "        # Ajouter la docstring si elle existe\n",
    "        if metadata[\"doc\"]:\n",
    "            content = metadata[\"doc\"] + \"\\n\\n\" + content\n",
    "\n",
    "    texts.append(content)\n",
    "    metadatas.append({\"source\": metadata.get(\"file\", \"inconnu\")})\n",
    "\n",
    "\n",
    "# Construire lâ€™index vectoriel\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "vectorstore = Chroma.from_texts(texts, embeddings, metadatas=metadatas)\n",
    "\n",
    "print(\"âœ… Index crÃ©Ã© avec\", len(texts), \"documents\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6ff80a-1474-4de7-9f46-1bbd019bd4c7",
   "metadata": {},
   "source": [
    "Recherche avec un modÃ¨le local Ollama (Mistral)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d71d38eb-2260-4514-af6d-8145fd41f828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¤– RÃ©ponse Mistral:\n",
      "  The provided code is a Python library called Requests that allows you to send and receive HTTP responses from various servers using a simple and elegant API. It supports multiple HTTP methods such as GET, POST, PUT, DELETE, etc., and it handles tasks like adding query strings, form-encoding data, handling cookies, and more, making it easy for developers to interact with HTTP resources.\n",
      "\n",
      "It also comes with features like connection pooling, TLS/SSL verification, basic & digest authentication, and automatic content decompression and decoding. Requests is one of the most popular Python packages, and it's widely used in building robust and reliable HTTP-speaking applications.\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import Ollama\n",
    "\n",
    "# Mistral via Ollama\n",
    "llm = Ollama(model=\"mistral\")\n",
    "\n",
    "# Exemple de recherche\n",
    "query = \"How does the code handle HTTP requests?\"\n",
    "\n",
    "# 1. RÃ©cupÃ©rer les passages similaires\n",
    "results = vectorstore.similarity_search(query, k=3)\n",
    "\n",
    "# 2. Construire un prompt avec le contexte\n",
    "context = \"\\n\\n\".join([r.page_content for r in results])\n",
    "prompt = f\"Context:\\n{context}\\n\\nQuestion: {query}\\nAnswer:\"\n",
    "\n",
    "# 3. Lancer la gÃ©nÃ©ration locale\n",
    "answer = llm(prompt)\n",
    "print(\"ðŸ¤– RÃ©ponse Mistral:\\n\", answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "85623d11-2130-4634-8869-b9585c5363a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import Ollama\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "llm = Ollama(model=\"mistral\")\n",
    "\n",
    "def ask_code_agent(question: str, k: int = 3):\n",
    "    # 1. Recherche contexte\n",
    "    results = vectorstore.similarity_search(question, k=k)\n",
    "    context = \"\\n\\n\".join([r.page_content for r in results])\n",
    "\n",
    "    # 2. Prompt\n",
    "    prompt = f\"\"\"You are an AI code assistant.\n",
    "Answer the question based only on the context below.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "Answer in Markdown with code blocks if needed.\n",
    "\"\"\"\n",
    "\n",
    "    # 3. Stream Ollama (texte brut)\n",
    "    stream = llm.stream(prompt)\n",
    "\n",
    "    # Affichage progressif\n",
    "    display_handle = display(Markdown(\"\"), display_id=True)\n",
    "    full_output = \"\"\n",
    "\n",
    "    for token in stream:  # Ollama envoie du texte\n",
    "        full_output += token\n",
    "        display_handle.update(Markdown(full_output))\n",
    "\n",
    "    return full_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2c0525e6-bfc9-441c-9653-756725636105",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       " The code handles HTTP requests using theRequests library in Python. It allows you to send GET and POST requests easily, as shown in the example provided:\n",
       "\n",
       "```python\n",
       ">>> import requests\n",
       ">>> r = requests.get('https://www.python.org')\n",
       ">>> r.status_code\n",
       "200\n",
       ">>> b'Python is a programming language' in r.content\n",
       "True\n",
       "```\n",
       "\n",
       "The `requests.get()` function sends a GET request to the specified URL, and the response is stored in the `r` variable. The response status code can be accessed with `r.status_code`, and the content of the response can be checked using `r.content`.\n",
       "\n",
       "For more advanced HTTP requests like POST, PUT, DELETE etc., you can use the corresponding functions provided by the Requests library:\n",
       "\n",
       "```python\n",
       ">>> payload = dict(key1='value1', key2='value2')\n",
       ">>> r = requests.post('https://httpbin.org/post', data=payload)\n",
       ">>> print(r.text)\n",
       "...\n",
       "\"form\": {\n",
       "  \"key1\": \"value1\",\n",
       "  \"key2\": \"value2\"\n",
       "}\n",
       "...\n",
       "```\n",
       "\n",
       "You can find more details and supported features in the API Reference and User Guide available at <https://requests.readthedocs.io>."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = ask_code_agent(\"How does the code handle HTTP requests?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9da72d8e-280a-40c2-a8c4-2e56ff86cd64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       " The context provided does not contain any information related to \"Salut Mistral\". It seems like it is a documentation for the Python HTTP library called Requests, which includes its license, features, and usage instructions. There is no apparent connection between Requests and \"Salut Mistral\"."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = ask_code_agent(\"Salut mistral\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398a2119-ae7f-4beb-b4f7-6f1fdf9c30b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
